{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model Training Finale.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"SFYk0FOIhrWk","colab_type":"code","outputId":"649e2bb4-fff4-44db-fd32-90d48d6b991d","executionInfo":{"status":"ok","timestamp":1553096621363,"user_tz":-330,"elapsed":39940,"user":{"displayName":"Nithish Balachandar","photoUrl":"","userId":"11673492507565107492"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","! cp 'gdrive/My Drive/Ab_Summarization/Our_Own_Code/Seq2Seq Combos/Seq2Seq.py' ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"LRzBq9Q7hxff","colab_type":"code","outputId":"e3fb0672-3955-4694-9cde-73ed6e50ad61","executionInfo":{"status":"ok","timestamp":1553096622763,"user_tz":-330,"elapsed":13925,"user":{"displayName":"Nithish Balachandar","photoUrl":"","userId":"11673492507565107492"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","import time\n","import shutil\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","print('TensorFlow Version: {}'.format(tf.__version__))\n","\n","from Seq2Seq import Seq2Seq_Model"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow Version: 1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"7fpMtqbPhzKG","colab_type":"text"},"cell_type":"markdown","source":["**The different types of experiments**\n","\n","<ol>\n","  <li> Type 1 - emb-pos, bahdanau, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 2 - emb-pos, luong, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 3 - emb-pos, bahdanau, beam(10), 2 enc-dec, 128 units </li>\n","  <li> Type 4 - emb-pos, luong, beam(10), 2 enc-dec, 128 units </li>\n","  <li> Type 5 - emb, bahdanau, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 6 - emb, luong, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 7 - emb, bahdanau, beam(10), 2 enc-dec, 128 units </li>\n","  <li> Type 8 - emb, luong, beam(10), 2 enc-dec, 128 units </li>\n","  <li> Type 9 - emb, None, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 10 - emb, None, beam(10), 2 enc-dec, 128 units </li>\n","  <li> Type 11 - emb-pos, None, greedy, 2 enc-dec, 128 units </li>\n","  <li> Type 12 - emb-pos, None, beam(10), 2 enc-dec, 128 units </li>\n"," </ol>"]},{"metadata":{"id":"rYtCqaJ1iVm4","colab_type":"code","colab":{}},"cell_type":"code","source":["def pad_sentence_batch(sentence_batch, vocab_to_int):\n","    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n","    max_sentence = max([len(sentence) for sentence in sentence_batch])\n","    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n","\n","def get_batches(summaries, texts, batch_size, vocab_to_int):\n","    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n","    for batch_i in range(0, len(texts)//batch_size):\n","        start_i = batch_i * batch_size\n","        summaries_batch = summaries[start_i:start_i + batch_size]\n","        texts_batch = texts[start_i:start_i + batch_size]\n","        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch, vocab_to_int))\n","        pad_texts_batch = np.array(pad_sentence_batch(texts_batch, vocab_to_int))\n","        \n","        # Need the lengths for the _lengths parameters\n","        pad_summaries_lengths = []\n","        for summary in summaries_batch:\n","            pad_summaries_lengths.append(len(summary))\n","        \n","        pad_texts_lengths = []\n","        for text in texts_batch:\n","            pad_texts_lengths.append(len(text))\n","        \n","        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LkHH5k7-h0WO","colab_type":"code","colab":{}},"cell_type":"code","source":["def full_model_run(type_val):\n","  \n","  path = 'gdrive/My Drive/Ab_Summarization/Our_Own_Code/sumdata/train/'\n","  ckpt_path = \"gdrive/My Drive/Ab_Summarization/Our_Own_Code/Seq2Seq Combos/Model_Checkpoints_Final/\"\n","\n","  if 1 in [c in type_val for c in ['1','2','3','4','11','12']]:\n","    emb_name = 'word_embedding_matrix1'\n","  else:\n","    emb_name = 'word_embedding_matrix'\n","\n","  if 1 in [c in type_val for c in ['1','3','5','7']]:\n","    attn = 'Bahdanau'\n","  else:\n","    attn = 'Luong'\n","\n","  if 1 in [c in type_val for c in ['1','2','5','6','9','11']]:\n","    dec_mech = 'greedy'\n","  else:\n","    dec_mech = 'beam'\n","\n","  if 1 in [c in type_val for c in ['9','10','11','12']]:\n","    attn = None\n","    \n","  sorted_summaries = pickle.load(open(path+'summaries.pkl', 'rb'))\n","  sorted_texts = pickle.load(open(path+'texts.pkl', 'rb'))\n","  word_embedding_matrix = pickle.load(open(path+emb_name, 'rb'))\n","  vocab_to_int = pickle.load(open(path+'vocab_to_int', 'rb'))\n","  int_to_vocab = pickle.load(open(path+'int_to_vocab', 'rb'))\n","  \n","  print(\"1. Loaded the data\")\n","  \n","  params = {\n","      'attention_mechanism':attn, #Luong, Bahdanau, None\n","      'batch_size':128,\n","      'bidirectional':True, #False, True\n","      'cell_type':'LSTM',\n","      'embeddings':word_embedding_matrix,\n","      'vocab_size':word_embedding_matrix.shape[0],\n","      'inference_mechanism':dec_mech, #beam, greedy\n","      'num_decoder_layers':2,\n","      'num_encoder_layers':2,\n","      'num_units':128,\n","      'end_token':'<EOS>',\n","      'beam_size':10,\n","      'word2int':vocab_to_int\n","  }\n","\n","  if not os.path.exists(os.path.join(ckpt_path,type_val)):\n","    os.makedirs(os.path.join(ckpt_path,type_val))\n","    print(\"2. Created new directory for this type\")\n","  else:\n","    for f in os.listdir(os.path.join(ckpt_path,type_val)):\n","      shutil.copy2(os.path.join(ckpt_path,type_val,f),\"./\")\n","    print(\"2. Copied exisiting checkpoints\")\n","  \n","  ob = Seq2Seq_Model(params)\n","  train_graph = ob.build_graph()\n","  \n","  print(\"3. Contructed the graph\")\n","    \n","  # choose number of samples\n","  sorted_sum = sorted_summaries[:1000000]\n","  sorted_tex = sorted_texts[:1000000]\n","  del sorted_summaries, sorted_texts\n","  \n","  split = int(0.7*len(sorted_sum))\n","  train_summaries, test_summaries = sorted_sum[:300000], sorted_sum[split:]\n","  train_texts, test_texts = sorted_tex[:300000], sorted_tex[split:]\n","  del sorted_sum, sorted_tex\n","  \n","  # Train the Model\n","  learning_rate = 0.005\n","  learning_rate_decay = 0.95\n","  min_learning_rate = 0.0005\n","  stop_early = 0 \n","  batch_loss = []\n","\n","  checkpoint = \"final_best_model_multigraph.ckpt\"\n","\n","  with tf.Session(graph=train_graph) as sess:\n","    saver = tf.train.Saver()\n","    if os.path.isfile(\"./\"+checkpoint+\".index\"):\n","      saver.restore(sess,\"./\"+checkpoint)\n","\n","    else:\n","      sess.run(tf.global_variables_initializer())\n","    writer = tf.summary.FileWriter(\"./Logs/Seq2Seq\", sess.graph)\n","\n","    for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n","        get_batches(train_summaries, train_texts, params['batch_size'], vocab_to_int)):\n","      start_time = time.time()\n","      _, loss = sess.run(\n","          [ob.train_op, ob.cost],\n","          {ob.encoder_inputs: texts_batch,\n","           ob.decoder_targets: summaries_batch,\n","           ob.learning_rate: learning_rate,\n","           ob.decoder_lengths: summaries_lengths,\n","           ob.encoder_lengths: texts_lengths})\n","      print(\"Batch No. %4d of %d Current Loss %.4f Time %0.3f\"%(batch_i+1,int(len(train_summaries)/params['batch_size']),loss,time.time()-start_time))\n","\n","      #Reduce learning rate, but not below its minimum value\n","      if(batch_i % 20 == 0):\n","        learning_rate *= learning_rate_decay\n","        if learning_rate < min_learning_rate:\n","          learning_rate = min_learning_rate\n","\n","      # Saving for every few batches\n","      if batch_i % 500 == 0:\n","        print(\"New Checkpoint Created for this batch\")\n","        saver.save(sess, \"./\"+checkpoint)\n","\n","    saver.save(sess, \"./\"+checkpoint)\n","    \n","  print(\"4. Finished training\")\n","  \n","  for f in os.listdir():\n","    if checkpoint.split(\".\")[0] in f or f == 'checkpoint':\n","      shutil.copy2(\"./\"+f,os.path.join(ckpt_path,type_val))\n","      os.remove(\"./\"+f)\n","      \n","  print(\"5. Copied checkpoints to drive\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yGGv0QdWlBhC","colab_type":"code","colab":{}},"cell_type":"code","source":["# train all types for 1 epoch\n","for i in range(1,13):\n","  print(\"--------------------------------------------------------------------------------------------------------\")\n","  type_val = \"type\"+str(i)\n","  print(type_val)\n","  full_model_run(type_val)\n","  print(\"--------------------------------------------------------------------------------------------------------\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mNT517IBUJ1K","colab_type":"code","colab":{}},"cell_type":"code","source":["# train any 1 particular type\n","type_val = 'type8'\n","full_model_run(type_val)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cl7t5S4Mxhd5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}